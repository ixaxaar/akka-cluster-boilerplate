spark {
  # The Spark master host. Set first by environment if exists. Then system, then config.
  # Options: spark://host1:port1,host2:port2
  # - "local" to run locally with one thread,
  # - local[4]" to run locally with 4 cores
  # - the master IP/hostname to run on a Spark standalone cluster
  # - if not set, defaults to "local[*]" to run with enough threads
  # Supports optional HA failover for more than one: host1,host2..
  # which is used to inform: spark://host1:port1,host2:port2
  master = "local[4]"
  # cleaner.ttl = ${?SPARK_CLEANER_TTL}

  # The batch interval must be set based on the latency requirements
  # of your application and available cluster resources.
  # streaming.batch.interval = ${?SPARK_STREAMING_BATCH_INTERVAL}
}
